/**
 * Enhanced Local OCR Demo (100% Offline)
 *
 * æ–¹æ¡ˆï¼šTesseract.js + Sharp é¢„å¤„ç†
 * æ”¯æŒï¼šMac ARM/Intel, Windows ARM/x64
 * è¯­è¨€ï¼šä¸­è‹±æ–‡æ··åˆ
 */

import { createWorker } from "tesseract.js";
import sharp from "sharp";
import * as fs from "fs";
import * as path from "path";

interface OCRResult {
  success: boolean;
  text: string;
  duration: number;
  confidence: number;
  preprocessTime: number;
  recognizeTime: number;
}

/**
 * å›¾åƒé¢„å¤„ç† - æå‡ OCR è¯†åˆ«ç‡çš„å…³é”®
 */
async function preprocessImage(inputPath: string): Promise<Buffer> {
  const startTime = performance.now();

  const result = await sharp(inputPath)
    .greyscale() // è½¬ç°åº¦
    .normalize() // å½’ä¸€åŒ–å¯¹æ¯”åº¦
    .sharpen({ sigma: 1 }) // è½»åº¦é”åŒ–
    .linear(1.2, -20) // æé«˜å¯¹æ¯”åº¦
    .toBuffer();

  console.log(`   ğŸ¨ Pre-processing: ${(performance.now() - startTime).toFixed(0)}ms`);
  return result;
}

/**
 * æ‰§è¡Œ OCR
 */
async function performOCR(imagePath: string, lang: string = "eng"): Promise<OCRResult> {
  const totalStart = performance.now();

  // 1. é¢„å¤„ç†å›¾åƒ
  console.log("   ğŸ“· Processing image...");
  const preprocessStart = performance.now();
  const processedBuffer = await preprocessImage(imagePath);
  const preprocessTime = performance.now() - preprocessStart;

  // 2. åˆå§‹åŒ– Worker
  console.log(`   â³ Loading Tesseract (lang: ${lang})...`);
  const worker = await createWorker(lang, 1, {
    logger: (m) => {
      if (m.status === "recognizing text") {
        process.stdout.write(`\r   ğŸ” Recognizing: ${(m.progress * 100).toFixed(0)}%`);
      }
    },
  });

  try {
    // 3. è¯†åˆ«
    const recognizeStart = performance.now();
    const {
      data: { text, confidence },
    } = await worker.recognize(processedBuffer);
    const recognizeTime = performance.now() - recognizeStart;

    console.log(""); // æ¢è¡Œ

    return {
      success: true,
      text: text.trim(),
      confidence,
      duration: performance.now() - totalStart,
      preprocessTime,
      recognizeTime,
    };
  } finally {
    await worker.terminate();
  }
}

async function main() {
  const args = process.argv.slice(2);
  const imagePath = args.find((a) => !a.startsWith("--"));

  // è§£æè¯­è¨€å‚æ•°
  let lang = "eng"; // é»˜è®¤è‹±æ–‡
  const langArg = args.find((a) => a.startsWith("--lang="));
  if (langArg) {
    lang = langArg.split("=")[1];
  } else if (args.includes("--chi")) {
    lang = "chi_sim";
  } else if (args.includes("--both")) {
    lang = "eng+chi_sim";
  }

  if (!imagePath) {
    console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           Enhanced Local OCR Demo (100% Offline)           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Usage:
  npx tsx demo/ocr-demo.ts <image_path> [options]

Options:
  --lang=<code>   Specify language (e.g., eng, chi_sim, eng+chi_sim)
  --chi           Use Simplified Chinese
  --both          Use both English and Chinese
  --export        Export result to JSON

Examples:
  npx tsx demo/ocr-demo.ts image.png              # English only
  npx tsx demo/ocr-demo.ts image.png --chi        # Chinese only
  npx tsx demo/ocr-demo.ts image.png --both       # Both languages
`);
    return;
  }

  console.log("\n" + "=".repeat(60));
  console.log("âœ¨ Enhanced Local OCR Demo (100% Offline)");
  console.log("=".repeat(60));
  console.log(`ğŸ“ Image: ${path.basename(imagePath)}`);
  console.log(`ğŸŒ Language: ${lang}`);
  console.log("-".repeat(60));

  try {
    const result = await performOCR(imagePath, lang);

    console.log(`\nâœ… Success!`);
    console.log(`   â±ï¸  Total: ${(result.duration / 1000).toFixed(2)}s`);
    console.log(`   ğŸ¯ Confidence: ${result.confidence.toFixed(1)}%`);
    console.log(
      `   ğŸ“Š Preprocess: ${result.preprocessTime.toFixed(0)}ms | Recognize: ${(result.recognizeTime / 1000).toFixed(2)}s`
    );

    console.log(`\nğŸ“„ Recognized Text:`);
    console.log("â”€".repeat(40));
    const preview =
      result.text.length > 2000 ? result.text.substring(0, 2000) + "..." : result.text;
    console.log(preview || "[No text detected]");

    // å¯¼å‡º
    if (args.includes("--export")) {
      const outPath = imagePath.replace(/\.[^.]+$/, "_ocr.json");
      fs.writeFileSync(outPath, JSON.stringify(result, null, 2));
      console.log(`\nğŸ’¾ Exported to: ${outPath}`);
    }
  } catch (err) {
    console.log(`\nâŒ Failed: ${err}`);
  }

  console.log("=".repeat(60) + "\n");
}

main().catch(console.error);
